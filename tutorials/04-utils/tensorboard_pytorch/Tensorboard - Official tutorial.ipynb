{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "model = torchvision.models.resnet50(False) #\n",
    "\n",
    "# Have ResNet model take in grayscale rather than RGB\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "grid = torchvision.utils.make_grid(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `make_grid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([3, 242, 242])\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_image('images', grid, 0)\n",
    "writer.add_graph(model, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `add_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_text('lstm', 'This is an lstm', 0)\n",
    "writer.add_text('rnn', 'This is an rnn', 10)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `add_embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyword\n",
    "import torch\n",
    "meta = []\n",
    "while len(meta)<100:\n",
    "    meta = meta+keyword.kwlist # get some strings\n",
    "meta = meta[:100]\n",
    "\n",
    "for i, v in enumerate(meta):\n",
    "    meta[i] = v+str(i)\n",
    "\n",
    "label_img = torch.rand(100, 3, 10, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    label_img[i]*=i/100.0\n",
    "\n",
    "writer.add_embedding(torch.randn(100, 5), metadata=meta, label_img=label_img, global_step=0)\n",
    "writer.add_embedding(torch.randn(100, 5), label_img=label_img, global_step=10)\n",
    "writer.add_embedding(torch.randn(100, 5), metadata=meta, global_step=20)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
